{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h62B0cx0s6FT",
        "outputId": "0eb08196-6a41-495e-bd5c-86973530c551"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjGyTX6NupaB",
        "outputId": "90a1cf39-2a97-495e-c077-2d13435656a9"
      },
      "source": [
        "%cd sample_data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOa-BJiuty40"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeBpwFapub0x"
      },
      "source": [
        "df = pd.read_csv('cancer.csv',header=None)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls5P0YfRu97W",
        "outputId": "9fa14c36-30a1-4085-b3aa-60fdbeb110e2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 698 entries, 0 to 697\n",
            "Data columns (total 11 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   1000025  698 non-null    int64 \n",
            " 1   5        698 non-null    int64 \n",
            " 2   1        698 non-null    int64 \n",
            " 3   1.1      698 non-null    int64 \n",
            " 4   1.2      698 non-null    int64 \n",
            " 5   2        698 non-null    int64 \n",
            " 6   1.3      698 non-null    object\n",
            " 7   3        698 non-null    int64 \n",
            " 8   1.4      698 non-null    int64 \n",
            " 9   1.5      698 non-null    int64 \n",
            " 10  2.1      698 non-null    int64 \n",
            "dtypes: int64(10), object(1)\n",
            "memory usage: 60.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H907lSuv4Bt"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz2Scbghv_it"
      },
      "source": [
        "df = df[~df[6].isin(['?'])]                              #eliminate rows that contain ?\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5LLC1uJyTsT"
      },
      "source": [
        "df = df.astype(float)\n",
        "df.iloc[:,10].replace(2, 0,inplace=True)                 #changing from 2 to 0 in column 10\n",
        "df.iloc[:,10].replace(4, 1,inplace=True)                 #changing from 4 to 1\n",
        "\n",
        "scaled_df=df\n",
        "names = df.columns[0:10]\n",
        "scaler = MinMaxScaler()                                     # applying normalization\n",
        "scaled_df = scaler.fit_transform(df.iloc[:,0:10])          #when we train the network, we will pick that column from the original df dataframe\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=names)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt_l5uhgym-c"
      },
      "source": [
        "\n",
        "X_train=scaled_df.iloc[0:500,1:10].values\n",
        "y_train=df.iloc[0:500,10:].values\n",
        "\n",
        "X_test=scaled_df.iloc[501:683,1:10].values\n",
        "y_test=df.iloc[501:683,10:].values"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0kUeAuey4i2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ-MhTQLzMLJ",
        "outputId": "76db548d-20a0-43f0-d16f-b71c0fbee029"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1L6WBJjzzb6",
        "outputId": "59b920ba-d2e8-4554-8634-9f62af275ab4"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUN1wERJz3vE"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(units=9,activation='relu'))\n",
        "\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "\n",
        "model.add(Dense(units=7,activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "# For a binary classification problem\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hZ137vp0Xh9",
        "outputId": "82150a65-5bb1-4ecf-acd3-a6c8b7ed0c29"
      },
      "source": [
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stop]\n",
        "          )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 0.6669 - val_loss: 0.6545\n",
            "Epoch 2/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.6229\n",
            "Epoch 3/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.5842\n",
            "Epoch 4/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5653 - val_loss: 0.5378\n",
            "Epoch 5/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5113 - val_loss: 0.4828\n",
            "Epoch 6/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4604 - val_loss: 0.4201\n",
            "Epoch 7/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - val_loss: 0.3524\n",
            "Epoch 8/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3476 - val_loss: 0.2832\n",
            "Epoch 9/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2766 - val_loss: 0.2217\n",
            "Epoch 10/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2306 - val_loss: 0.1694\n",
            "Epoch 11/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1968 - val_loss: 0.1318\n",
            "Epoch 12/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1790 - val_loss: 0.1030\n",
            "Epoch 13/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1444 - val_loss: 0.0849\n",
            "Epoch 14/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1505 - val_loss: 0.0709\n",
            "Epoch 15/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1173 - val_loss: 0.0608\n",
            "Epoch 16/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1331 - val_loss: 0.0546\n",
            "Epoch 17/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1178 - val_loss: 0.0486\n",
            "Epoch 18/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1133 - val_loss: 0.0462\n",
            "Epoch 19/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0982 - val_loss: 0.0419\n",
            "Epoch 20/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1387 - val_loss: 0.0396\n",
            "Epoch 21/600\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0919 - val_loss: 0.0369\n",
            "Epoch 22/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0960 - val_loss: 0.0341\n",
            "Epoch 23/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0976 - val_loss: 0.0327\n",
            "Epoch 24/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 0.0311\n",
            "Epoch 25/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1071 - val_loss: 0.0305\n",
            "Epoch 26/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0986 - val_loss: 0.0296\n",
            "Epoch 27/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1085 - val_loss: 0.0278\n",
            "Epoch 28/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0955 - val_loss: 0.0265\n",
            "Epoch 29/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1224 - val_loss: 0.0260\n",
            "Epoch 30/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0864 - val_loss: 0.0270\n",
            "Epoch 31/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0995 - val_loss: 0.0251\n",
            "Epoch 32/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1002 - val_loss: 0.0244\n",
            "Epoch 33/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0239\n",
            "Epoch 34/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1086 - val_loss: 0.0242\n",
            "Epoch 35/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0903 - val_loss: 0.0234\n",
            "Epoch 36/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1043 - val_loss: 0.0234\n",
            "Epoch 37/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1015 - val_loss: 0.0224\n",
            "Epoch 38/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.0216\n",
            "Epoch 39/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0924 - val_loss: 0.0215\n",
            "Epoch 40/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0851 - val_loss: 0.0214\n",
            "Epoch 41/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1172 - val_loss: 0.0223\n",
            "Epoch 42/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.0212\n",
            "Epoch 43/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0207\n",
            "Epoch 44/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.0207\n",
            "Epoch 45/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0812 - val_loss: 0.0211\n",
            "Epoch 46/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0205\n",
            "Epoch 47/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1028 - val_loss: 0.0209\n",
            "Epoch 48/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1019 - val_loss: 0.0204\n",
            "Epoch 49/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0756 - val_loss: 0.0200\n",
            "Epoch 50/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1078 - val_loss: 0.0204\n",
            "Epoch 51/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0964 - val_loss: 0.0196\n",
            "Epoch 52/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.0203\n",
            "Epoch 53/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0187\n",
            "Epoch 54/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0191\n",
            "Epoch 55/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0891 - val_loss: 0.0194\n",
            "Epoch 56/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1015 - val_loss: 0.0192\n",
            "Epoch 57/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0957 - val_loss: 0.0190\n",
            "Epoch 58/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0771 - val_loss: 0.0195\n",
            "Epoch 59/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0202\n",
            "Epoch 60/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0196\n",
            "Epoch 61/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0870 - val_loss: 0.0192\n",
            "Epoch 62/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0660 - val_loss: 0.0186\n",
            "Epoch 63/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0932 - val_loss: 0.0193\n",
            "Epoch 64/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0626 - val_loss: 0.0193\n",
            "Epoch 65/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0751 - val_loss: 0.0188\n",
            "Epoch 66/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0628 - val_loss: 0.0180\n",
            "Epoch 67/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0194\n",
            "Epoch 68/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0188\n",
            "Epoch 69/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0182\n",
            "Epoch 70/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0732 - val_loss: 0.0186\n",
            "Epoch 71/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0754 - val_loss: 0.0175\n",
            "Epoch 72/600\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1014 - val_loss: 0.0180\n",
            "Epoch 73/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0637 - val_loss: 0.0181\n",
            "Epoch 74/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.0179\n",
            "Epoch 75/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0667 - val_loss: 0.0177\n",
            "Epoch 76/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0862 - val_loss: 0.0181\n",
            "Epoch 77/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0819 - val_loss: 0.0184\n",
            "Epoch 78/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0702 - val_loss: 0.0175\n",
            "Epoch 79/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.0169\n",
            "Epoch 80/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0764 - val_loss: 0.0178\n",
            "Epoch 81/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0860 - val_loss: 0.0176\n",
            "Epoch 82/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0677 - val_loss: 0.0170\n",
            "Epoch 83/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0517 - val_loss: 0.0167\n",
            "Epoch 84/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.0169\n",
            "Epoch 85/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.0169\n",
            "Epoch 86/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0755 - val_loss: 0.0175\n",
            "Epoch 87/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0159\n",
            "Epoch 88/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0826 - val_loss: 0.0170\n",
            "Epoch 89/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.0171\n",
            "Epoch 90/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0694 - val_loss: 0.0168\n",
            "Epoch 91/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.0163\n",
            "Epoch 92/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0563 - val_loss: 0.0163\n",
            "Epoch 93/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0543 - val_loss: 0.0162\n",
            "Epoch 94/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0163\n",
            "Epoch 95/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.0168\n",
            "Epoch 96/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0916 - val_loss: 0.0168\n",
            "Epoch 97/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0594 - val_loss: 0.0160\n",
            "Epoch 98/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.0164\n",
            "Epoch 99/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0862 - val_loss: 0.0160\n",
            "Epoch 100/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0861 - val_loss: 0.0165\n",
            "Epoch 101/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0790 - val_loss: 0.0165\n",
            "Epoch 102/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0498 - val_loss: 0.0157\n",
            "Epoch 103/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0842 - val_loss: 0.0162\n",
            "Epoch 104/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0904 - val_loss: 0.0162\n",
            "Epoch 105/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.0155\n",
            "Epoch 106/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0689 - val_loss: 0.0159\n",
            "Epoch 107/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0699 - val_loss: 0.0156\n",
            "Epoch 108/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0534 - val_loss: 0.0150\n",
            "Epoch 109/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0157\n",
            "Epoch 110/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0165\n",
            "Epoch 111/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0158\n",
            "Epoch 112/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0589 - val_loss: 0.0155\n",
            "Epoch 113/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0765 - val_loss: 0.0154\n",
            "Epoch 114/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0154\n",
            "Epoch 115/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0685 - val_loss: 0.0155\n",
            "Epoch 116/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.0158\n",
            "Epoch 117/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0646 - val_loss: 0.0154\n",
            "Epoch 118/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0597 - val_loss: 0.0155\n",
            "Epoch 119/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.0153\n",
            "Epoch 120/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.0155\n",
            "Epoch 121/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 0.0164\n",
            "Epoch 122/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0785 - val_loss: 0.0155\n",
            "Epoch 123/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0763 - val_loss: 0.0157\n",
            "Epoch 124/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0605 - val_loss: 0.0154\n",
            "Epoch 125/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0538 - val_loss: 0.0152\n",
            "Epoch 126/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0150\n",
            "Epoch 127/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0622 - val_loss: 0.0158\n",
            "Epoch 128/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0638 - val_loss: 0.0154\n",
            "Epoch 129/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0757 - val_loss: 0.0157\n",
            "Epoch 130/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0559 - val_loss: 0.0147\n",
            "Epoch 131/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0156\n",
            "Epoch 132/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - val_loss: 0.0157\n",
            "Epoch 133/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0608 - val_loss: 0.0155\n",
            "Epoch 134/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - val_loss: 0.0156\n",
            "Epoch 135/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0715 - val_loss: 0.0159\n",
            "Epoch 136/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0742 - val_loss: 0.0155\n",
            "Epoch 137/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0149\n",
            "Epoch 138/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0633 - val_loss: 0.0159\n",
            "Epoch 139/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0170\n",
            "Epoch 140/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.0156\n",
            "Epoch 141/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0822 - val_loss: 0.0162\n",
            "Epoch 142/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0813 - val_loss: 0.0155\n",
            "Epoch 143/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.0163\n",
            "Epoch 144/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0155\n",
            "Epoch 145/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0550 - val_loss: 0.0159\n",
            "Epoch 146/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.0154\n",
            "Epoch 147/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0761 - val_loss: 0.0156\n",
            "Epoch 148/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0716 - val_loss: 0.0158\n",
            "Epoch 149/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0770 - val_loss: 0.0161\n",
            "Epoch 150/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.0149\n",
            "Epoch 151/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0666 - val_loss: 0.0154\n",
            "Epoch 152/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.0150\n",
            "Epoch 153/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0762 - val_loss: 0.0155\n",
            "Epoch 154/600\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0732 - val_loss: 0.0153\n",
            "Epoch 155/600\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.0155\n",
            "Epoch 00155: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb951f3dc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "n8xJWP0p0p7k",
        "outputId": "7f1a3ae3-3fe2-4717-ed88-06659c5e782c"
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb951d42cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZ2_Vs82HAe"
      },
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsGzIvjE2eA8"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3myG6wn2fIA",
        "outputId": "540a74e5-99d4-48c6-9ecd-5bc369fa92c1"
      },
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[140   1]\n",
            " [  0  41]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}